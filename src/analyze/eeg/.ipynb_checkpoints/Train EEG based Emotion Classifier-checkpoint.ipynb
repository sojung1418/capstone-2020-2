{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from CustomDatasetClass import * # EEG_Dataset, get_train_test_set()\n",
    "from Models import * # CNN \n",
    "from TrainTestModule import * # train_model(), test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting\n",
    "* lin_len 지우고, 자동 계산으로 바꾸기..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset setting ===================\n",
    "data_type = \"fftMap\" # \"fftMap\", \"fd\"\n",
    "dataset = \"SEED\" # \"DEAP\", \"SEED\"\n",
    "split = \"10sec_5over\" # window sliding\n",
    "n_channel = 1 # input depth\n",
    "n_electrodes = 32 # (num of eeg sensor's electrodes)\n",
    "numOfClass = 3 # num of label\n",
    "# ==================================\n",
    "\n",
    "# model parameter ==================\n",
    "model_type =\"cla\" # \"reg\"\n",
    "lin_len = 884 if n_electrodes == 32 else 592 # vector's length after flattening # => 아 이건 계산하는걸로 바꾸자;\n",
    "out_len = 1 if model_type == \"reg\" else numOfClass\n",
    "# ===================================\n",
    "\n",
    "bs = 64 # batch size\n",
    "\n",
    "# not used for SEED dataset\n",
    "target = 0 # (V=0, A=1, D=2, L=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_path = \"InputData/\" + dataset + \"_\" + data_type + \"_\" + split + \".pickle\"\n",
    "meta_path = \"InputData/SEED_10sec_5over\"\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    eeg_dataset = pickle.load(f)\n",
    "\n",
    "if dataset == \"SEED\":\n",
    "    with open(meta_path + \"_ptc_to_idx\", 'rb') as f:\n",
    "        ptc_to_idx = pickle.load(f)\n",
    "    with open(meta_path + \"_idx_to_ptc\", 'rb') as f:\n",
    "        idx_to_ptc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 개수 =  9675\n",
      "데이터 하나의 shape =  (32, 41)\n",
      "레이블 example =  1\n"
     ]
    }
   ],
   "source": [
    "print(\"전체 데이터 개수 = \", len(eeg_dataset))\n",
    "print(\"데이터 하나의 shape = \", eeg_dataset[0][0].shape)\n",
    "print(\"레이블 example = \", eeg_dataset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label processing\n",
    "\n",
    "* if value > 5  then class = 1(High)\n",
    "* if value <= 5 then class = 0(Low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"cla\": \n",
    "    for i in range(len(eeg_dataset)):\n",
    "        if dataset == \"DEAP\":\n",
    "            V, A, D, L = eeg_dataset[i][1]\n",
    "            V = process_label(V, numOfClass); D = process_label(D, numOfClass); \n",
    "            A = process_label(A, numOfClass); L = process_label(L, numOfClass);\n",
    "            eeg_dataset[i][1] = [V,A,D,L]\n",
    "        elif dataset == \"SEED\": # already integer value\n",
    "            eeg_dataset[i][1] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traverse method\n",
    "* DEAP도 ptc_to_idx, idx_to_ptc 파일을 만들자,,코드 개더럽;; **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"DEAP\":\n",
    "    noc = len(eeg_dataset)//1280 # num of chunks\n",
    "    print(noc)\n",
    "\n",
    "    def get_data_index(p_id, t_id, c_id=0, noc=1):\n",
    "        return (noc * 40) * p_id + noc * t_id + c_id\n",
    "\n",
    "    def get_base_index(p_id, t_id):\n",
    "        return 40 * p_id + t_id\n",
    "\n",
    "    # get p_id, t_id, c_id\n",
    "    def from_data_index(index, noc=1):\n",
    "        p_id,remain = index // (noc*40), index % (noc*40)\n",
    "        return p_id, remain//noc, remain%noc\n",
    "\n",
    "elif dataset == \"SEED\":\n",
    "    def get_data_index(p_id, t_id, c_id=0, noc=0): # noc is not used\n",
    "        return ptc_to_idx[str(p_id+1) + \"-\" + str(t_id) + \"-\" + str(c_id)]\n",
    "\n",
    "    def get_base_index(p_id, t_id):\n",
    "        return 15 * p_id + t_id\n",
    "\n",
    "    # get p_id, t_id, c_id\n",
    "    def from_data_index(index, noc=0): # noc is not used\n",
    "        return idx_to_ptc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic train-test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOOCV_split(test_subject, eeg_dataset, target=0, noc=0):\n",
    "    # test_subject = Leave this participant out\n",
    "    train = []; test = []\n",
    "    \n",
    "    for idx in range(len(eeg_dataset)): \n",
    "        p_id, t_id, c_id = from_data_index(idx, noc) # *\n",
    "        \n",
    "        if p_id == test_subject:\n",
    "            test.append(eeg_dataset[idx])\n",
    "        else:\n",
    "            train.append(eeg_dataset[idx])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Epoch 1 ] T_Loss = 0.017046 \n",
      "      t/p       Low Neutral    High \n",
      "        Low   320.0     0.0   310.0 \n",
      "    Neutral   323.0     0.0   288.0 \n",
      "       High    53.0     0.0   641.0 \n",
      "V_loss = 0.017119  Acc = 49.6641 \n",
      "\n",
      "[ Epoch 2 ] T_Loss = 0.016426 \n",
      "      t/p       Low Neutral    High \n",
      "        Low   350.0    19.0   261.0 \n",
      "    Neutral   329.0    96.0   186.0 \n",
      "       High    80.0    13.0   601.0 \n",
      "V_loss = 0.016384  Acc = 54.1085 \n",
      "\n",
      "[ Epoch 3 ] T_Loss = 0.015800 \n",
      "      t/p       Low Neutral    High \n",
      "        Low   155.0   257.0   218.0 \n",
      "    Neutral    68.0   415.0   128.0 \n",
      "       High    27.0   104.0   563.0 \n",
      "V_loss = 0.015812  Acc = 58.5530 \n",
      "\n",
      "[ Epoch 4 ] T_Loss = 0.015314 \n",
      "      t/p       Low Neutral    High \n",
      "        Low   233.0   193.0   204.0 \n",
      "    Neutral   104.0   379.0   128.0 \n",
      "       High    43.0    76.0   575.0 \n",
      "V_loss = 0.015377  Acc = 61.3437 \n",
      "\n",
      "[ Epoch 5 ] T_Loss = 0.014904 \n",
      "      t/p       Low Neutral    High \n",
      "        Low   283.0   158.0   189.0 \n",
      "    Neutral   135.0   365.0   111.0 \n",
      "       High    58.0    58.0   578.0 \n",
      "V_loss = 0.015025  Acc = 63.3592 \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 1. get neural network\n",
    "net = CNN(n_channel, lin_len, out_len, n_electrodes, model_type)\n",
    "\n",
    "# 2. train : test split\n",
    "# train, test = LOOCV_split(test_subject, eeg_dataset) # LOOCV\n",
    "train, test = train_test_split(eeg_dataset, test_size=0.2) # 8 : 2\n",
    "\n",
    "# 3. get dataset instance\n",
    "trainset, trainloader, testset, testloader = get_train_test_set(train, test, bs, dataset)\n",
    "\n",
    "# 4. train a network\n",
    "net, t_loss_list, v_loss_list, f1_list, acc_list = train_model(net, model_type, trainloader, testloader, numOfClass, epoch=5, detail=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out-cross-validation over all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfParticipants = 32 if dataset == \"DEAP\" else 15\n",
    "\n",
    "for test_subject in range(0, numOfParticipants):\n",
    "    print(test_subject, \"에 대한 LOOCV 학습\")\n",
    "    net = CNN(n_channel, lin_len, out_len, n_electrodes, model_type)\n",
    "    \n",
    "    train, test = LOOCV_split(test_subject, eeg_dataset)\n",
    "    trainset, trainloader, testset, testloader = get_train_test_set(train, test, bs, dataset)\n",
    "    net, t_loss_list, v_loss_list, f1_list, acc_list = train_model(net, model_type, trainloader, testloader, numOfClass, epoch=5, detail=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
